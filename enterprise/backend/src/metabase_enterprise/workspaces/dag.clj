;; TODO consider renaming this to dataflow
(ns metabase-enterprise.workspaces.dag
  "Used to do graph computations with respect to dataflow within a workspace.

   This workspace should encapsulate all coupling to the [[metabase-enterprise.dependencies]] module, including through
   database artifacts.

   It is purely concerned with calculation, any side effects wanted as a result of the analysis should happen outside."
  (:require
   [metabase-enterprise.workspaces.util :as ws.u]
   [metabase.util :as u]))

(def ^:private RefId :string)

(def ^:private GraphMembers
  [:map
   [:working-set [:sequential ::RefId]]
   [:inputs [:sequential ::InputTable]]
   [:outputs [:sequential ::OutputTable]]
   [:entities [:sequential ::Entity]]])

(def ^:private Graph
  [:and GraphMembers [:dependencies [:map-of RefId [:sequential RefId]]]])

(def ^:private GraphUpdate [:map [:added GraphMembers] [:removed GraphMembers] [:subgraph Graph]])

;; goals for graph:
;; - enough to power all the apis without reading the appdb again
;; -

;; pros and cons of putting tables in the entities and / or dependencies data structures:
;; pro
;; - implicitly encodes sources and targets
;;
;; con
;; - mixed ref-ids with app-ids
;; - larger graph - more steps to walk, less human-readable
;; - can't get target for a particular transform without walking (but does guarantee uniqueness)
;;
;; what about putting it in
;;
;; app-id -> ref-id, or the reverse?

#_(def ^:private empty-subgraph
    {:working-set  []
     :inputs       []
     :outputs      []
     :entities     []
     :dependencies {}})

(defn unsupported-dependency?
  "Return "
  [{transform-ids :transform :as _entity-map}]
  (when (seq transform-ids)
    ;; return the set of transform ids for which there is a direct card dependency, or nil if there are none.
    ;; this can be done with a simple DISTINCT(downstream_id) WHERE down.transform & up.table (don't care about up.id)
    (not-empty #{(first transform-ids)})))

;;;; Public API

(defn- path-induced-subgraph
  "Given a map of entity types to IDs, compute the path-induced subgraph.
   `entities-by-type` is a map like {:transform [1 2 3]}.

   Returns a map with:
   - :working-set  - the entities being edited within the workspace, in topological order
                     {type, ref-id, parent-id}
   - :inputs       - tables that the subgraph directly depends on, that are not themselves produced by the subgraph.
                     ordered by id
   - :outputs      - isolated tables generated by entities in the subgraph, in topological order
                     {global, workspace}

   - :entities     - the path induced subgraph generated by the working set, in topological order
   - :dependencies - association list for the subgraph, with keys and values both in topological order"
  [working-set]
  {:working-set  (or working-set [{:type "transform", :ref-id "2", :parent-id 1}])
   :inputs       [{:database-id 1, :table-id 1, :schema "public", :table "orders"}]
   :outputs      [{:global    {:database-id 1
                               :table-id    [:maybe 2]
                               :schema      "public"
                               :table       "augmented_orders"}
                   :workspace {:transform-id "2"
                               :database-id  1
                               :table-id     [:maybe 3]
                               ;; These can be generated by pure functions, but let's not assume that.
                               :schema       "isolated__blah"
                               ;; TODO note that we can still get conflicts on these table names - how to handle that?
                               ;; Maybe we just detect there will be a conflict with this naming scheme, and throw.
                               ;; That's better than unexpected behavior...
                               :table        "public__augmented_orders"}}]
   ;; TODO do we need to put the tables in here? maybe we can just get sources from dependencies, and put outputs
   ;;      inside the transforms? or maybe it's enough that the outputs point back to them (hydrate will reverse this)
   :entities     [{:type   "transform", :ref-id "2"}
                  {:type   "table"}]
   ;; TODO note that in JSON this key will get turned into a string - not safe
   ;;      i guess we should serialize it as an ordered association list then.
   ;;      or, is there something better we can use as keys? e.g. "transform:2"
   :dependencies {{:type "transform", :ref-id "2"} []}})

(defn- validate-graph!
  [subgraph]
  ;; note: these are all things that are trivial to enforce though, maybe belong in normalization instead.
  ;; keys and values are topo sorted?
  ;; inputs and targets are disjoint
  )

(defn- from-appdb-entity
  "Return the trivial subgraph generated by a single entity"
  [type id]
  (ws.u/assert-transform! type)
  (let [ref-id         (str type ":" (inc id))
        source-table-1 {:id (+ id 2), :schema "upload", :table ref-id}
        target-table   {:id (+ id 3), :schema "output", :table ref-id, :source-ref-id ref-id}]
    {:working-set  [ref-id]
     :inputs       [source-table-1]
     :outputs      [target-table]
     :entities     [{:type type, :ref-id ref-id :source-id id}]
     :sources      {ref-id [source-table-1]}
     :dependencies {ref-id []}}))

(def ^:private db+schema+table (juxt :db_id :schema :table))

(defn- seek-by-key [entities k v]
  (u/seek (comp #{v} k) entities))

(defn- change-target
  [subgraph ref-id target]
  ;; check this is a valid output? (we need the graph for this)
  ;; find the old output, and remove it
  ;; add the new output
  ;; add it as dependency to all entities with this table as a source
  )

(defn add-entity
  "Update the subgraph when a new entity is added to the working set.
   No-op if the entity is already in the working set."
  [subgraph type id]
  (ws.u/assert-transform! type)
  (if-not subgraph
    (from-appdb-entity type id)
    (let [ref-id          (str type ":" (inc id))
          {:keys [working-set inputs outputs entities dependencies]} subgraph
          in-working-set? (when-let [ref-id (:ref-id (seek-by-key entities :source-id id))]
                            (boolean (some #{ref-id} working-set)))]
      (if in-working-set?
        ;; no-op
        {:added nil, :removed nil, :subgraph subgraph}
        ;; determine whether this entity is connected in either direction to anything in the working set.
        ;; if so, also add all connecting paths to the graph as well (both the entities and their corresponding edges)
        ;; to demonstrate everything that can change in a non-trivial example, we find both types of path here.
        (let [predecessor       (first (:working-set subgraph))
              descendant        (u/seek #(not= predecessor %) (:working-set subgraph))
              in-between        (when predecessor (str "transform:" (+ id 2)))
              source-table-1    {:db_id (if predecessor 2 1) :id (+ id 3), :schema "public", :table (str \t (+ id 3)), :tx-ref-id predecessor}
              target-table      {:db_id 2,                   :id (+ id 4), :schema "output", :table (str \t (+ id 4)), :tx-ref-id ref-id}
              in-between-source (when in-between {:db_id 2,  :id (+ id 5), :schema "output", :table (str \t (+ id 5)), :tx-ref-id in-between})
              in-between-target (when in-between {:db_id 2,  :id (+ id 6), :schema "output", :table (str \t (+ id 6)), :tx-ref-id in-between})
              outputs           (cond-> outputs in-between-target (conj in-between-target) true (conj target-table))
              ;; Using db.schema.table, since table might not exist yet.
              inputs'           (let [output? (into #{} (map db+schema+table) outputs)]
                                  (not-empty (vec (remove (comp output? db+schema+table)
                                                          (conj inputs in-between-source source-table-1)))))]
          {:added
           {:working-set [ref-id]
            :inputs      (seq (remove (set inputs) inputs'))
            :outputs     [target-table]
            :entities    (cond-> (list ref-id) predecessor (conj in-between) true vec)}

           :removed
           {:working-set nil
            :inputs      (seq (remove (set inputs') inputs))
            :outputs     nil
            :entities    nil}

           :subgraph
           ;; Append the adjacency lists and walk the graph to recompute these properly.
           {:working-set  (conj working-set ref-id)
            :inputs       inputs'
            :outputs      outputs
            :entities     (cond-> (seq entities)
                            true        (conj {:type type,        :ref-id ref-id, :source-id id})
                            ;; These should all have source-ids, since they must have come from the global graph.
                            predecessor (conj {:type "transform", :ref-id in-between}
                                              {:type "transform", :ref-id predecessor})
                            descendant  (conj {:type "transform", :ref-id descendant})
                            true distinct
                            true vec)
            :dependencies (cond-> dependencies
                            predecessor (assoc ref-id [in-between]
                                               in-between [predecessor])
                            descendant (update descendant u/conjv ref-id))}})))))

;; tests:
;; - add transform to a nil / empty subgraph (both?)
;; - add transform that is already in working set
;; - add transform that is already in subgraph (through the closure only)
;; - add transform that will add an input, and remove another (by masking it with an output), and add another tx to closure
;; (probably one non-trivial case like the above is enough coverage of edge cases?)

;; TODO what should we do if deleting this entity would cause the graph to break?
;;      just yolo, let the dependency checker show warnings to the user / execution won't run, or runs only partially?
(defn remove-entity
  "Update the subgraph when a new entity is added to the working set.
   No-op if the entity is not already in the working set."
  [subgraph ref-id]
  ;; no-op if not in the working set
  ;; remove from working set
  ;; optimization: if we have reference counting, could more cheaply knock out stale nodes from the graph.
  ;; for now, we can just recompute using :working-set and :dependencies, then filter :dependencies based on :entities
  ;; note: it might still be in the subgraph afterward, by being in a path.
  (update subgraph :working-set #(filterv (comp #{ref-id} :ref-id) %)))

;; tests:
;; - remove entity from nil / empty subgraph (just special cases of the next one)
;; - remove entity that is not in the non-trivial subgraph
;; - remove entity that is in the working set of just itself
;; - remove entity that will remove another tx, remove an input, and restore another input (masked by an output)
;; - remove entity that is in the subgraph, but not in the working set (no-op)

;; TODO should we return just the subgraph from add and remove, and let caller diff from previous graph?
;;      we could provide helper methods that do the diffing.
;;      the alternative: return the diffs in addition to the whole value
;;      the latter may be more expensive when we don't need a bit of the diff, but should typically be cheaper than
;;      computing the. it would also shrinks the surface area of the api - so let's go for it.

(defn- diff-graphs [before after]
  {:input-tables-to-grant-access-to  (remove (set (:inputs before)) (:inputs after))
   :input-tables-to-revoke-access-to (remove (set (:inputs after)) (:inputs before))
   ;; TODO probably we can move to not doing any of this? without mbql we won't need table ids yet
   :output-tables-to-copy            (remove (set (:outputs before)) (:outputs after))
   :output-tables-to-delete          (remove (set (:outputs after)) (:outputs before))
   ;; Well, we definitely already know this (at most a singleton, taken directly from args)
   :copies-to-make                   (remove (set (:working-set before)) (:working-set after))
   :copies-to-delete                 (remove (set (:working-set after)) (:working-set before))
   ;; ... I think that's all, if we're using the graph as the source of truth?
   ;; ... but more realistically, there are probably some appdb tables generated by the representation that we want
   ;; ... e.g. joins between the appdb and workspace stuff
   })

;; TODO do we actually need this? if we only add transforms one at a time when they're edited, this is overkill.
#_(defn- appdb->path-induced-subgraph
    "Given some global entities in the app-db, return the generated subgraph where we've turne"
    [entities-map]
    (#_not-quite path-induced-subgraph (or entities-map {:transforms [1]})))

;; TODO not sure we need this - everything is incremental right now.
;;      this kind of batch thing is perhaps an optimization?
#_(defn- update-working-set
    [entities-map-to-add entity-refs-to-remove subgraph]
    (or entities-map-to-add [{:transforms [1]}])
    (or entity-refs-to-remove ["transform:2"])

    ;; deletes obsolete entities from the working set
    ;; validates that no added entities are already in graph, or just filters them out.
    ;; fetches relevant dependency graph related to new entities
    ;; merges the appdb and workspace graphs (shadowing overwritten nodes and edges)

    ;; recomputes or amends the subgraph

    subgraph)

(defn hydrate-graph
  "Given the return shape of path-induced-subgraph (TODO make this a malli type), wrap it in a larger structure with
   computed indexes, corresponding toucan models, etc."
  [subgraph]
  {:subgraph                subgraph
   ;; TODO lock down this shape, just some ideas here.
   ;; Used to remap source references on execution
   :global->isolated-tables {}
   ;; Used to show
   :isolated->global-tables {}})

;; TODO: which of these flows is best?
;;
;; validation (e.g. sorry this pulls in an mbql transform, or a transform->card dep)
;;
;; 1. after computing graph (least efficient on compute, most efficient on database if OK, slowest overall)
;; 2. while computing graph (most efficient if OK, makes graph code less pure)
;; 3. before computing graph (most wasteful if OK, fastest if not OK)
;;
;; I think (1) is the most straight forward to do first, and we can consider 2 or 3 as optimizations?
